    # 手术机器人自动导航项目技术大纲

## 一、项目概述

### 1.1 项目目标

通过DSA医学影像+AI算法，实现介入手术机器人的自动导航功能，完成导丝的推送和旋转动作自动化。

### 1.2 现有基础

- ✅ 手术机器人硬件平台（上位机+下位机）
- ✅ CAN/CANopen通信协议
- ✅ 下位机电机控制（推送+旋转）
- ❌ 图像理解与路径规划
- ❌ 自动导航控制逻辑

### 1.3 技术路线

```
DSA图像 → 血管分割 → 路径规划 → 运动控制 → 机器人执行
```

## 二、系统架构

### 2.1 整体架构图

```
┌─────────────┐     ┌─────────────┐     ┌─────────────┐
│  DSA影像    │────▶│  AI处理     │────▶│  路径规划   │
│  采集系统   │     │  (分割/识别) │     │  (轨迹生成) │
└─────────────┘     └─────────────┘     └─────────────┘
                                               │
                                               ▼
┌─────────────┐     ┌─────────────┐     ┌─────────────┐
│  机器人     │◀────│  CAN桥接    │◀────│  ROS2       │
│  (已实现)   │     │  节点       │     │  控制节点   │
└─────────────┘     └─────────────┘     └─────────────┘
```

### 2.2 数据流

1. **影像输入**：DICOM格式DSA图像（2D/3D）
2. **AI处理**：血管分割mask + 中心线提取
3. **路径规划**：离散点序列 {推送距离, 旋转角度, 时间戳}
4. **控制指令**：CAN PDO消息（位置/速度指令）
5. **执行反馈**：编码器位置、力矩、状态

## 三、快速实施路线（6周计划）

### 🚀 Phase 0：环境准备（第1周）

- [ ] WSL2/Ubuntu 22.04 + CUDA环境
- [ ] ROS2 Humble安装配置
- [ ] Python 3.10 + PyTorch环境
- [ ] CAN工具链（socketCAN/PCAN）

### 🚀 Phase 1：控制接口验证（第1-2周）

**目标**：验证轨迹文件→机器人运动的通路

#### 任务清单

- [ ] 创建ROS2工作空间
- [ ] 编写轨迹播放节点（CSV→ROS2 topic）
- [ ] 编写CAN桥接节点（ROS2→CANopen）
- [ ] 单轴运动测试
- [ ] 双轴协调运动测试

#### 关键代码结构

```
trajectory_control/
├── src/
│   ├── trajectory_player.cpp    # CSV轨迹播放
│   ├── can_bridge_node.cpp      # ROS2-CAN桥接
│   └── safety_monitor.cpp       # 安全监控
├── config/
│   ├── can_config.yaml          # CAN配置
│   └── robot_limits.yaml        # 运动限制
└── test/
    └── test_trajectories/       # 测试轨迹文件
```

### 🚀 Phase 2：血管分割快速原型（第3-4周）

**目标**：从DSA图像中提取血管路径

#### 任务清单

- [ ] 准备训练数据（20-30例）
- [ ] nnUNet环境配置与训练
- [ ] 模型推理服务搭建
- [ ] 中心线提取算法
- [ ] 路径平滑与采样

#### 训练配置

```yaml
dataset:
  name: vessel_seg_demo
  samples: 30
  modality: DSA
  
model:
  architecture: nnUNet_3d_lowres
  epochs: 100
  batch_size: 2
  
inference:
  device: cuda
  precision: fp16
  target_time: <100ms
```

### 🚀 Phase 3：路径规划实现（第4-5周）

**目标**：将血管中心线转换为机器人运动指令

#### 任务清单

- [ ] 坐标系标定（图像→机器人）
- [ ] 路径点采样（0.5mm间隔）
- [ ] 速度规划（梯形/S型）
- [ ] 推送-旋转解耦算法
- [ ] 碰撞检测（可选）

#### 规划算法（规则版）

```python
def plan_trajectory(centerline_points):
    trajectory = []
    for i in range(1, len(centerline_points)):
        # 计算推送距离
        push_dist = distance(points[i], points[i-1])
      
        # 计算旋转角度
        tangent = compute_tangent(points[i-1], points[i])
        rotation = atan2(tangent.y, tangent.x)
      
        # 添加轨迹点
        trajectory.append({
            'push_mm': push_dist,
            'rotate_deg': rotation,
            'time_ms': i * 10  # 10ms间隔
        })
    return trajectory
```

### 🚀 Phase 4：系统集成测试（第5-6周）

**目标**：闭环验证与性能优化

#### 任务清单

- [ ] 仿真环境搭建（Gazebo/Unity）
- [ ] 硅胶血管模型测试
- [ ] 延迟测试（<200ms全链路）
- [ ] 精度测试（<1mm误差）
- [ ] 异常处理测试

## 四、技术栈速查

### 4.1 核心依赖

| 模块     | 技术选型  | 版本要求  | 用途     |
| -------- | --------- | --------- | -------- |
| 操作系统 | Ubuntu    | 22.04 LTS | 开发环境 |
| 中间件   | ROS2      | Humble    | 模块通信 |
| AI框架   | PyTorch   | ≥2.0     | 模型训练 |
| 医学影像 | MONAI     | ≥1.3     | 数据处理 |
| 分割模型 | nnUNet    | v2        | 血管分割 |
| CAN通信  | SocketCAN | -         | 硬件接口 |
| 仿真     | Gazebo    | Garden    | 算法验证 |

### 4.2 快速安装脚本

```bash
# 基础环境
sudo apt update && sudo apt install -y \
    build-essential cmake git python3-pip \
    can-utils libpcan-dev

# ROS2 Humble
sudo apt install -y ros-humble-desktop \
    ros-humble-ros2-control \
    ros-humble-gazebo-ros2-control

# Python环境
conda create -n surgical_nav python=3.10
conda activate surgical_nav
pip install torch torchvision monai nnunet
```

## 五、关键技术点

### 5.1 坐标系对齐

- **问题**：DSA图像坐标→机器人世界坐标
- **方案**：手眼标定 + 标定板
- **精度要求**：<0.5mm

### 5.2 实时性保证

- **目标**：全链路延迟<200ms
- **分解**：
  - 图像分割：<80ms
  - 路径规划：<20ms
  - 通信传输：<10ms
  - 控制响应：<90ms

### 5.3 安全机制

- **软件限位**：关节角度/速度限制
- **力矩监控**：异常碰撞检测
- **急停按钮**：硬件级中断
- **手动接管**：控制权切换

## 六、里程碑与交付物

### M1：控制验证（第2周）

- 交付：机器人按CSV轨迹运动视频
- 指标：轨迹跟踪误差<0.5mm

### M2：分割模型（第4周）

- 交付：训练好的nnUNet模型
- 指标：Dice系数>0.85

### M3：闭环演示（第6周）

- 交付：DSA图像→自动导航完整演示
- 指标：硅胶模型通过率>80%

## 七、风险与对策

| 风险项       | 影响     | 缓解措施              |
| ------------ | -------- | --------------------- |
| 分割精度不足 | 路径错误 | 增加训练数据+人工审核 |
| 实时性不达标 | 控制延迟 | 模型剪枝+硬件升级     |
| 坐标系误差   | 导航偏差 | 多点标定+实时校正     |
| CAN通信丢包  | 运动异常 | 冗余设计+错误重传     |

## 八、学习资源

### 必读文档

1. [ROS2 Humble官方教程](https://docs.ros.org/en/humble/)
2. [nnUNet v2使用指南](https://github.com/MIC-DKFZ/nnUNet)
3. [CANopen协议速查](https://www.can-cia.org/canopen/)

### 推荐课程

1. 鱼香ROS2（B站）- ROS2快速入门
2. MONAI Bootcamp - 医学影像处理
3. 深蓝学院 - 机器人运动规划

### 参考项目

1. [ros2_control_demos](https://github.com/ros-controls/ros2_control_demos)
2. [MONAI Label](https://github.com/Project-MONAI/MONAILabel)
3. [surgical_robotics_challenge](https://github.com/surgical-robotics-ai)

## 九、快速启动命令

```bash
# 1. 克隆项目模板
git clone https://github.com/your-repo/surgical-nav-template
cd surgical-nav-template

# 2. 构建ROS2包
colcon build --symlink-install
source install/setup.bash

# 3. 启动控制节点
ros2 launch trajectory_control demo_launch.py

# 4. 运行分割推理
python3 inference_server.py --model ./models/best_model.pth

# 5. 开始自动导航
ros2 run navigation_core auto_guidance_node
```

---

**下一步行动**：

1. 今天：搭建开发环境（WSL2 + ROS2）
2. 明天：编写第一个轨迹播放节点
3. 本周末：完成CAN通信测试

💡 **记住**：先跑通最简单的"CSV轨迹→机器人运动"，这是一切的基础！